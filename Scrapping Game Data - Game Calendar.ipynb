{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrapping WNBA game data (first part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.common.exceptions import WebDriverException"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all game IDs from WNBA website (2010-2022):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBA data from our original dataset goes from the 2003-04 season to 2022-23 season. In the WNBA website, we only have data from 2010 forward.\n",
    "\n",
    "We won't scrape data from 2023 since the NBA dataset also doesn't contain that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# List to collect all gameIDs:\n",
    "gameIDs = []\n",
    "\n",
    "# Iterate through years from 2010 to 2022\n",
    "for year in range(2010, 2023):\n",
    "\n",
    "    # Construct the URL for the specific year\n",
    "    url = f\"https://www.wnba.com/schedule?season={year}&month=all\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait time so that page has time to fully load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Wait until needed elements are present\n",
    "    games_section = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"Schedule_gameSectionContainer__CED5h\")))\n",
    "\n",
    "    # Element where we can find information about each gameID, in its \"href\" attribute \n",
    "    games = driver.find_element(By.CLASS_NAME, \"Schedule_gameSectionContainer__CED5h\")\n",
    "    a_elements = games.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "    for a_element in a_elements:\n",
    "        href = a_element.get_attribute(\"href\")\n",
    "\n",
    "        # Filter data so that it only includes NBA teams (exclude games from foreign national teams)\n",
    "        if href and re.search(r\"/game/\\d+/[A-Z]{3}-vs-[A-Z]{3}$\", href):\n",
    "            #print(href)\n",
    "            gameID = href.split(\"/\")[-2]\n",
    "            gameIDs.append(gameID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put gameIDs in CSV so that we don't have to run the code above several times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGameIDs = pd.DataFrame({\"WNBA GameID\": gameIDs})\n",
    "dfGameIDs.to_csv(\"WNBAGameIDs.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get game data for each gameID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA = pd.read_csv(\"WNBAGameIDs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Create empty lists to store values\n",
    "team_names = []\n",
    "game_dates = []\n",
    "seasons_1 = [] # first format of season identificator, similar to the NBA dataset\n",
    "seasons_2 = [] # second format of season identificator, similar to the NBA dataset\n",
    "away_teams = []\n",
    "home_teams = []\n",
    "current_urls = []\n",
    "\n",
    "# Iterate through years from 2010 to 2023\n",
    "for game_id in WNBA[\"WNBA GameID\"]:\n",
    "    try:\n",
    "        # Create a new instance of the Chrome driver\n",
    "        base_url = 'https://www.wnba.com/game'\n",
    "        url = f'{base_url}/{game_id}'\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for 5 seconds for the page to fully load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Handle HTTP 502 responses\n",
    "        if \"502 Bad Gateway\" in driver.title:\n",
    "            print(f\"502 Bad Gateway error for GameID: {game_id}\")\n",
    "            # Wait for 10 minutes before proceeding to the next ID\n",
    "            time.sleep(600)\n",
    "            driver = webdriver.Chrome()\n",
    "            base_url = 'https://www.wnba.com/game'\n",
    "            url = f'{base_url}/{game_id}'\n",
    "            driver.get(url)\n",
    "            continue\n",
    "\n",
    "        # Retrieve the current URL and store it in a variable, to extract data from it\n",
    "        current_url = driver.current_url\n",
    "\n",
    "        # Find elements with required data and retrieve data from them\n",
    "        home_team_element = driver.find_element(By.CLASS_NAME, \"_GameDetailsHeader--team__home_166ax_290\")\n",
    "        TEAM_NAME = home_team_element.text\n",
    "        TEAM_NAME = TEAM_NAME.replace('\\n', ' ')\n",
    "        team_names.append(TEAM_NAME)\n",
    "\n",
    "        current_urls.append(current_url)\n",
    "\n",
    "        game_date_element = driver.find_element(By.CLASS_NAME, \"_GameStatusExpanded__date_iiqdo_20\")\n",
    "        GAME_DATE = game_date_element.text\n",
    "\n",
    "        GAME_DATE = datetime.strptime(GAME_DATE, \"%A, %b %d, %Y\")\n",
    "        GAME_DATE = GAME_DATE.strftime(\"%m-%d-%Y\")\n",
    "        game_dates.append(GAME_DATE)\n",
    "\n",
    "        SEASON_1 = GAME_DATE[6:]\n",
    "        seasons_1.append(SEASON_1)\n",
    "\n",
    "        year = int(SEASON_1)\n",
    "        previous_year = year - 1\n",
    "\n",
    "        last_two_digits = str(SEASON_1)[-2:]\n",
    "        SEASON_2 = f\"{previous_year}-{last_two_digits}\"\n",
    "        seasons_2.append(SEASON_2)\n",
    "\n",
    "        current_url = driver.current_url\n",
    "        teams = current_url.split(\"/\")[-1].split(\"-vs-\")\n",
    "        AWAY_TEAM = teams[0]\n",
    "        HOME_TEAM = teams[1]\n",
    "\n",
    "        away_teams.append(AWAY_TEAM)\n",
    "        home_teams.append(HOME_TEAM)\n",
    "\n",
    "    # Handle other possible problems\n",
    "    except WebDriverException as e:\n",
    "        print(f\"Error occurred for GameID {game_id}: {str(e)}\")\n",
    "        # Wait for 10 minutes before proceeding to the next ID\n",
    "        time.sleep(600)\n",
    "        driver = webdriver.Chrome()\n",
    "        base_url = 'https://www.wnba.com/game'\n",
    "        url = f'{base_url}/{game_id}'\n",
    "        driver.get(url)\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe with all data, in the same format as the NBA dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"TEAM_NAME\": team_names,\n",
    "    \"GAME_DATE\": game_dates,\n",
    "    \"SEASON_1\": seasons_1,\n",
    "    \"SEASON_2\": seasons_2,\n",
    "    \"AWAY_TEAM\": away_teams,\n",
    "    \"HOME_TEAM\": home_teams,\n",
    "    \"GAME_ID\": current_urls\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and adding data for the skipped gameIDs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct GAME_ID column, extracting the IDs from the hrefs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GAME_ID\"] = df['GAME_ID'].str.extract(r'(\\d+)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have spatial data available for shots from 2016 forward. Since we aim to have a dataset with the same data as the NBA dataset, we will filter the WNBA dataset so that it only includes data from 2016 forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the row where WNBA GameID is equal to 1041700101\n",
    "index_of_first_game_2016 = WNBA.index[WNBA['WNBA GameID'] == 1011600001][0]\n",
    "\n",
    "# Create a new DataFrame with rows from the found index onward\n",
    "WNBA_2016_forward = WNBA.loc[index_of_first_game_2016:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA_2016_forward[WNBA_2016_forward.duplicated()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA_2016_forward.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ran the code before using Web Driver in order to retrieve game data for each GameID, some IDs were skipped when we got a 502 response or when there was a WebDriverException. Therefore, we should now check what GAME_IDs have missing data due to that error in previous code, and retrieve that missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values in 'WNBA GameID' column to string type\n",
    "WNBA_2016_forward['WNBA GameID'] = WNBA_2016_forward['WNBA GameID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find values in \"WNBA GameID\" that are not in \"GAME_ID\" and store them\n",
    "missing_data = WNBA_2016_forward[~WNBA_2016_forward['WNBA GameID'].isin(df['GAME_ID'])]['WNBA GameID'].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code again for the missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Create empty lists to store values\n",
    "team_names_missing_data = []\n",
    "game_dates_missing_data = []\n",
    "seasons_1_missing_data = []\n",
    "seasons_2_missing_data = []\n",
    "away_teams_missing_data = []\n",
    "home_teams_missing_data = []\n",
    "current_urls_missing_data = []\n",
    "\n",
    "# Iterate through years from 2010 to 2023\n",
    "for game_id in list(missing_data):\n",
    "    try:\n",
    "        # Create a new instance of the Chrome driver\n",
    "        base_url = 'https://www.wnba.com/game'\n",
    "        url = f'{base_url}/{game_id}'\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for 5 seconds for the page to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Handle HTTP 502 responses\n",
    "        if \"502 Bad Gateway\" in driver.title:\n",
    "            print(f\"502 Bad Gateway error for GameID: {game_id}\")\n",
    "            # Wait for 10 minutes before proceeding to the next ID\n",
    "            time.sleep(600)\n",
    "            driver = webdriver.Chrome()\n",
    "            base_url = 'https://www.wnba.com/game'\n",
    "            url = f'{base_url}/{game_id}'\n",
    "            driver.get(url)\n",
    "            continue\n",
    "\n",
    "        # Retrieve the current URL and store it in a variable\n",
    "        current_url = driver.current_url\n",
    "\n",
    "        # Your code to extract data and append it to the respective lists\n",
    "        home_team_element = driver.find_element(By.CLASS_NAME, \"_GameDetailsHeader--team__home_166ax_290\")\n",
    "        TEAM_NAME = home_team_element.text\n",
    "        TEAM_NAME = TEAM_NAME.replace('\\n', ' ')\n",
    "        team_names_missing_data.append(TEAM_NAME)\n",
    "\n",
    "        current_urls_missing_data.append(current_url)\n",
    "\n",
    "        game_date_element = driver.find_element(By.CLASS_NAME, \"_GameStatusExpanded__date_iiqdo_20\")\n",
    "        GAME_DATE = game_date_element.text\n",
    "\n",
    "        GAME_DATE = datetime.strptime(GAME_DATE, \"%A, %b %d, %Y\")\n",
    "        GAME_DATE = GAME_DATE.strftime(\"%m-%d-%Y\")\n",
    "        game_dates_missing_data.append(GAME_DATE)\n",
    "\n",
    "        SEASON_1 = GAME_DATE[6:]\n",
    "        seasons_1_missing_data.append(SEASON_1)\n",
    "\n",
    "        year = int(SEASON_1)\n",
    "        previous_year = year - 1\n",
    "\n",
    "        last_two_digits = str(SEASON_1)[-2:]\n",
    "        SEASON_2 = f\"{previous_year}-{last_two_digits}\"\n",
    "        seasons_2_missing_data.append(SEASON_2)\n",
    "\n",
    "        current_url = driver.current_url\n",
    "        teams = current_url.split(\"/\")[-1].split(\"-vs-\")\n",
    "        AWAY_TEAM = teams[0]\n",
    "        HOME_TEAM = teams[1]\n",
    "\n",
    "        away_teams_missing_data.append(AWAY_TEAM)\n",
    "        home_teams_missing_data.append(HOME_TEAM)\n",
    "\n",
    "        print(current_url)\n",
    "\n",
    "    # Handle other exceptions\n",
    "    except WebDriverException as e:\n",
    "        print(f\"Error occurred for GameID {game_id}: {str(e)}\")\n",
    "        # Wait for 10 minutes before proceeding to the next ID\n",
    "        time.sleep(600)\n",
    "        driver = webdriver.Chrome()\n",
    "        base_url = 'https://www.wnba.com/game'\n",
    "        url = f'{base_url}/{game_id}'\n",
    "        driver.get(url)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = {\n",
    "    \"TEAM_NAME\": team_names_missing_data,\n",
    "    \"GAME_DATE\": game_dates_missing_data,\n",
    "    \"SEASON_1\": seasons_1_missing_data,\n",
    "    \"SEASON_2\": seasons_2_missing_data,\n",
    "    \"AWAY_TEAM\": away_teams_missing_data,\n",
    "    \"HOME_TEAM\": home_teams_missing_data,\n",
    "    \"GAME_ID\": current_urls_missing_data\n",
    "}\n",
    "\n",
    "df_missing_data = pd.DataFrame(missing_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct GAME_ID column, following same logic as before (extract the gameID from the href we collected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_data[\"GAME_ID\"] = df_missing_data['GAME_ID'].str.extract(r'(\\d+)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new df with all games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games_df = pd.concat([df, df_missing_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA_2016_forward.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create final dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values in \"WNBA GameID\" column of WNBA_2016_forward to string format\n",
    "WNBA_2016_forward['WNBA GameID'] = WNBA_2016_forward['WNBA GameID'].astype(str)\n",
    "\n",
    "# Convert values in \"GAME_ID\" column of all_games_df to string format\n",
    "all_games_df['GAME_ID'] = all_games_df['GAME_ID'].astype(str)\n",
    "\n",
    "# Merge the dataframes based on the specified columns\n",
    "final_df = pd.merge(WNBA_2016_forward, all_games_df, how='left', left_on='WNBA GameID', right_on='GAME_ID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since we merged the two dataframes, we will have two columns with the GameID. Therefore, we will drop one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop('GAME_ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.rename(columns = {\"WNBA GameID\": \"GAME_ID\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get final data into CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"WNBA_2016_2023_Shots.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify games that belong to the regular season"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on, we concluded that our NBA dataset only contains regular season data. In order to follow the same structure for the WNBA dataset so that we can compare the two leagues, we will filter the data we have so that we only have regular season data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to retrieve from each year's game schedule web page which part of the season each gameID belongs to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# List to collect all gameIDs:\n",
    "gameIDs = []\n",
    "part_of_season = []\n",
    "\n",
    "# Iterate through years from 2016 to 2022\n",
    "for year in range(2016, 2023):\n",
    "\n",
    "    # Construct the URL for the specific year\n",
    "    url = f\"https://www.wnba.com/schedule?season={year}&month=all&team=all\"\n",
    "    \n",
    "    # Navigate to the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait so that page can fully load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Find elements with the data we want to retrieve\n",
    "    games = driver.find_element(By.CLASS_NAME, \"Schedule_gameSectionContainer__CED5h\")\n",
    "\n",
    "    a_elements = driver.find_elements(By.CLASS_NAME, \"_GameTile__game-info_s6mxa_54\")\n",
    "    \n",
    "    season_elements = games.find_elements(By.CLASS_NAME, \"_GameTile__details_s6mxa_76\")\n",
    "    \n",
    "    for a_element, season_element in zip(a_elements, season_elements):\n",
    "\n",
    "        season_info = season_element.text\n",
    "        season_info = season_info.splitlines()[0]\n",
    "        part_of_season.append(season_info)\n",
    "\n",
    "        href = a_element.get_attribute(\"href\")\n",
    "\n",
    "        # Extract from the href attribute of each element the corresponding gameID\n",
    "        if href and re.search(r\"/game/\\d+/[A-Z]{3}-vs-[A-Z]{3}$\", href):\n",
    "            gameID = href.split(\"/\")[-2]\n",
    "            gameIDs.append(gameID)\n",
    "        \n",
    "        else:\n",
    "            gameIDs.append(\"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular_season_games = pd.DataFrame({\"GameID\": gameIDs, \"Season\": part_of_season})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter dataframe to include only regular season data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1021600001</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1021600002</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1021600003</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1021600004</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1021600005</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1022200212</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1022200213</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1022200215</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1022200214</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1022200216</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GameID          Season\n",
       "15    1021600001  Regular Season\n",
       "16    1021600002  Regular Season\n",
       "17    1021600003  Regular Season\n",
       "18    1021600004  Regular Season\n",
       "19    1021600005  Regular Season\n",
       "...          ...             ...\n",
       "1513  1022200212  Regular Season\n",
       "1514  1022200213  Regular Season\n",
       "1515  1022200215  Regular Season\n",
       "1516  1022200214  Regular Season\n",
       "1517  1022200216  Regular Season\n",
       "\n",
       "[1236 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where game is 'Regular Season'\n",
    "df_regular_season_games = df_regular_season_games[df_regular_season_games['Season'] == 'Regular Season']\n",
    "df_regular_season_games"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CSV with IDs from regular season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular_season_games.to_csv(\"regular_season_gameIDs_WNBA.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data so that it matches the NBA dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the following filtering actions:\n",
    "\n",
    " - Remove games from 2023 (2023-24 season), since the NBA dataset only contains games until that season.\n",
    " - Remove games that don't belong to the regular season, since the NBA dataset only contains regular season shots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from previous CSVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA_2016_2022_shots = pd.read_csv(\"WNBA_2016_2023_Shots.csv\", index_col = 0)\n",
    "regular_season_gameIDs = pd.read_csv(\"regular_season_gameIDs_WNBA.csv\", index_col = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove games from 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA_2016_2022_shots = WNBA_2016_2022_shots[WNBA_2016_2022_shots[\"SEASON_1\"] != 2023]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove games that do not belong to the regular season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes based on the common column \"WNBA GameID\"\n",
    "WNBA_2016_2022_shots = pd.merge(WNBA_2016_2022_shots, regular_season_gameIDs, how='left', left_on='WNBA GameID', right_on='GameID')\n",
    "\n",
    "# Drop the duplicate \"GameID\" column if needed\n",
    "WNBA_2016_2022_shots.drop(columns=['GameID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA_2016_2022_shots = WNBA_2016_2022_shots[WNBA_2016_2022_shots[\"Season\"] == \"Regular Season\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>SEASON_1</th>\n",
       "      <th>SEASON_2</th>\n",
       "      <th>AWAY_TEAM</th>\n",
       "      <th>HOME_TEAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021600001</td>\n",
       "      <td>Indiana Fever</td>\n",
       "      <td>05-14-2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>DAL</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021600002</td>\n",
       "      <td>Washington Mystics</td>\n",
       "      <td>05-15-2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>NYL</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021600003</td>\n",
       "      <td>Minnesota Lynx</td>\n",
       "      <td>05-15-2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>PHO</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021600004</td>\n",
       "      <td>Chicago Sky</td>\n",
       "      <td>05-15-2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>CON</td>\n",
       "      <td>CHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021600005</td>\n",
       "      <td>Las Vegas Aces</td>\n",
       "      <td>05-15-2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>ATL</td>\n",
       "      <td>SAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1022200212</td>\n",
       "      <td>New York Liberty</td>\n",
       "      <td>08-14-2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NYL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>1022200213</td>\n",
       "      <td>Washington Mystics</td>\n",
       "      <td>08-14-2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>IND</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1022200215</td>\n",
       "      <td>Las Vegas Aces</td>\n",
       "      <td>08-14-2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>SEA</td>\n",
       "      <td>LVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1022200214</td>\n",
       "      <td>Phoenix Mercury</td>\n",
       "      <td>08-14-2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>CHI</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1022200216</td>\n",
       "      <td>Los Angeles Sparks</td>\n",
       "      <td>08-15-2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>DAL</td>\n",
       "      <td>LAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1236 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GAME_ID           TEAM_NAME   GAME_DATE  SEASON_1 SEASON_2 AWAY_TEAM   \n",
       "0     1021600001       Indiana Fever  05-14-2016      2016  2015-16       DAL  \\\n",
       "1     1021600002  Washington Mystics  05-15-2016      2016  2015-16       NYL   \n",
       "2     1021600003      Minnesota Lynx  05-15-2016      2016  2015-16       PHO   \n",
       "3     1021600004         Chicago Sky  05-15-2016      2016  2015-16       CON   \n",
       "4     1021600005      Las Vegas Aces  05-15-2016      2016  2015-16       ATL   \n",
       "...          ...                 ...         ...       ...      ...       ...   \n",
       "1231  1022200212    New York Liberty  08-14-2022      2022  2021-22       ATL   \n",
       "1232  1022200213  Washington Mystics  08-14-2022      2022  2021-22       IND   \n",
       "1233  1022200215      Las Vegas Aces  08-14-2022      2022  2021-22       SEA   \n",
       "1234  1022200214     Phoenix Mercury  08-14-2022      2022  2021-22       CHI   \n",
       "1235  1022200216  Los Angeles Sparks  08-15-2022      2022  2021-22       DAL   \n",
       "\n",
       "     HOME_TEAM  \n",
       "0          IND  \n",
       "1          WAS  \n",
       "2          MIN  \n",
       "3          CHI  \n",
       "4          SAN  \n",
       "...        ...  \n",
       "1231       NYL  \n",
       "1232       WAS  \n",
       "1233       LVA  \n",
       "1234       PHO  \n",
       "1235       LAS  \n",
       "\n",
       "[1236 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WNBA_2016_2022_shots.drop(columns=['Season'], inplace=True)\n",
    "WNBA_2016_2022_shots.reset_index(inplace = True, drop = True)\n",
    "WNBA_2016_2022_shots.rename(columns = {\"WNBA GameID\": \"GAME_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "WNBA_2016_2022_shots.to_csv(\"WNBA_2016_2022_shots.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "16faf5d188814dfbbcd16bd73887bd8f7b54eeaac1371d2de62a1f87840898cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
